{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMg78LxRCmFOPn1So/V0kVn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kirankumarpetlu/NLP/blob/main/NLPweek6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement chart parser using CYK algorihm for the grammars\n",
        "\n",
        "Grammers:\n",
        "1. Implement Chart parser using CYK algorithm for the grammars:\n",
        "* S->NP VP| NP AUXV VP\n",
        "* NP-> DET Noun | PNOUN | Noun\n",
        "* VP->  V  NP\n",
        "* PNOUN -> JOHN\n",
        "* AUXV -> is\n",
        "* V-> playing\n",
        "* Noun -> Game\n",
        "Ex: John is playing a game\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kihszEFI2GUp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irOg3DfFy-mT",
        "outputId": "79f09bbb-a7a7-465a-8b46-13e4b1e23032"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sentence \"John Is playing Game\" is NOT valid according to the grammar.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Grammar in CNF\n",
        "grammar = {\n",
        "    'S': ['NP VP', 'NP AUXV VP'],\n",
        "    'NP': ['DET NOM', 'PNOUN', 'NOUN'],\n",
        "    'VP': ['VERB NP', 'V NP'],\n",
        "    'PNOUN': ['JOHN'],\n",
        "    'AUXV': ['Is'],\n",
        "    'V': ['playing'],\n",
        "    'NOUN': ['Game'],\n",
        "    'DET': ['a'],\n",
        "    'NOM': ['game'],\n",
        "    'VERB': ['is']\n",
        "}\n",
        "\n",
        "# Reverse the grammar for easier lookup\n",
        "reverse_grammar = {}\n",
        "for lhs, rhs_list in grammar.items():\n",
        "    for rhs in rhs_list:\n",
        "        if rhs not in reverse_grammar:\n",
        "            reverse_grammar[rhs] = []\n",
        "        reverse_grammar[rhs].append(lhs)\n",
        "\n",
        "def cyk_parse(sentence):\n",
        "    words = sentence.split()\n",
        "    n = len(words)\n",
        "\n",
        "    # Initialize the CYK table\n",
        "    table = [[set() for _ in range(n)] for _ in range(n)]\n",
        "\n",
        "    # Fill the diagonal (length 1 substrings)\n",
        "    for i in range(n):\n",
        "        for lhs, rhs_list in grammar.items():\n",
        "            for rhs in rhs_list:\n",
        "                if words[i] == rhs:\n",
        "                    table[i][i].add(lhs)\n",
        "\n",
        "    # Fill the table for substrings of length 2 to n\n",
        "    for length in range(2, n+1):\n",
        "        for i in range(n - length + 1):\n",
        "            j = i + length - 1\n",
        "            for k in range(i, j):\n",
        "                for lhs, rhs_list in grammar.items():\n",
        "                    for rhs in rhs_list:\n",
        "                        if len(rhs.split()) == 2:\n",
        "                            B, C = rhs.split()\n",
        "                            if B in table[i][k] and C in table[k+1][j]:\n",
        "                                table[i][j].add(lhs)\n",
        "    return 'S' in table[0][n-1]\n",
        "\n",
        "# Test the CYK parser\n",
        "sentence = \"John Is playing Game\"\n",
        "if cyk_parse(sentence):\n",
        "    print(f'The sentence \"{sentence}\" is valid according to the grammar.')\n",
        "else:\n",
        "    print(f'The sentence \"{sentence}\" is NOT valid according to the grammar.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import CFG\n",
        "from nltk.parse import ChartParser\n",
        "# Define the CFG (Context-Free Grammar)\n",
        "grammar = CFG.fromstring(\"\"\"\n",
        "S -> NP VP\n",
        "NP -> DET NOM | PNOUN\n",
        "VP -> AUX V NP\n",
        "DET -> 'a' | 'the'\n",
        "NOM -> 'game'\n",
        "PNOUN -> 'John'\n",
        "AUX -> 'is'\n",
        "V -> 'playing'\n",
        "\"\"\")\n",
        "# Create a chart parser\n",
        "parser = ChartParser(grammar)\n",
        "# Input sentence (must match the grammar exactly)\n",
        "sentence = [\"John\", \"is\", \"playing\", \"a\", \"game\"]\n",
        "# Parse the sentence and display output\n",
        "for tree in parser.parse(sentence):\n",
        "    print(tree) # Print tree structure\n",
        "    tree.pretty_print() # Display tree visually # Indented this line"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1faQ4eC8XM9",
        "outputId": "bfee764e-6c45-4187-b9ab-7fa22011bf3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP (PNOUN John))\n",
            "  (VP (AUX is) (V playing) (NP (DET a) (NOM game))))\n",
            "       S                      \n",
            "   ____|_____                  \n",
            "  |          VP               \n",
            "  |     _____|_________        \n",
            "  NP   |     |         NP     \n",
            "  |    |     |      ___|___    \n",
            "PNOUN AUX    V    DET     NOM \n",
            "  |    |     |     |       |   \n",
            " John  is playing  a      game\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Implement Regex parser for the given sentences.\n",
        "   * The quick brown fox jumps over the lazy dog.\n",
        "   * NP->DT ADJ NN\n",
        "   * VP -> V NP | PP\n",
        "   * P-> IN\n",
        "   * V ->V\n",
        "   * PP-> IN NP"
      ],
      "metadata": {
        "id": "l9iUoOe82jEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Grammar rules as regex patterns\n",
        "grammar_patterns = {\n",
        "    \"DT\": r\"^(The|the)$\",  # Determiner\n",
        "    \"ADJ\": r\"^(quick|brown|lazy)$\",  # Adjective\n",
        "    \"NN\": r\"^(fox|dog)$\",  # Noun\n",
        "    \"V\": r\"^(jumps|jump)$\",  # Verb\n",
        "    \"IN\": r\"^(over)$\",  # Preposition\n",
        "}\n",
        "\n",
        "# Grammar rules for phrases\n",
        "grammar_rules = {\n",
        "    \"NP\": r\"DT ADJ NN\",  # Noun Phrase: Determiner + Adjective + Noun\n",
        "    \"VP\": r\"V NP|PP\",  # Verb Phrase: Verb + NP or Prepositional Phrase\n",
        "    \"PP\": r\"IN NP\",  # Prepositional Phrase: Preposition + Noun Phrase\n",
        "}\n",
        "\n",
        "def tokenize(sentence):\n",
        "    \"\"\"Tokenize the sentence into words.\"\"\"\n",
        "    return sentence.split()\n",
        "\n",
        "def match_word(word):\n",
        "    \"\"\"Match a word to its part of speech (POS) using regex.\"\"\"\n",
        "    for pos, pattern in grammar_patterns.items():\n",
        "        if re.match(pattern, word):\n",
        "            return pos\n",
        "    return None\n",
        "\n",
        "def parse_sentence(sentence):\n",
        "    \"\"\"Parse the sentence using regex patterns.\"\"\"\n",
        "    tokens = tokenize(sentence)\n",
        "    pos_tags = [match_word(token) for token in tokens]\n",
        "    print(\"Tokens:\", tokens)\n",
        "    pSSrint(\"POS Tags:\", pos_tags)\n",
        "\n",
        "    # Parse Noun Phrases (NP)\n",
        "    np_pattern = grammar_rules[\"NP\"].split()\n",
        "    np_matches = []\n",
        "    for i in range(len(pos_tags) - len(np_pattern) + 1):\n",
        "        if pos_tags[i:i + len(np_pattern)] == np_pattern:\n",
        "            np_matches.append((\" \".join(tokens[i:i + len(np_pattern)]), \"NP\"))\n",
        "\n",
        "    # Parse Prepositional Phrases (PP)\n",
        "    pp_pattern = grammar_rules[\"PP\"].split()\n",
        "    pp_matches = []\n",
        "    for i in range(len(pos_tags) - len(pp_pattern) + 1):\n",
        "        if pos_tags[i:i + len(pp_pattern)] == pp_pattern:\n",
        "            pp_matches.append((\" \".join(tokens[i:i + len(pp_pattern)]), \"PP\"))\n",
        "\n",
        "    # Parse Verb Phrases (VP)\n",
        "    vp_matches = []\n",
        "    for np_match in np_matches:\n",
        "        np_text, _ = np_match\n",
        "        for i in range(len(tokens)):\n",
        "            if tokens[i] in grammar_patterns[\"V\"] and tokens[i + 1:i + 1 + len(np_text.split())] == np_text.split():\n",
        "                vp_matches.append((f\"{tokens[i]} {np_text}\", \"VP\"))\n",
        "\n",
        "    # Combine all matches\n",
        "    matches = np_matches + pp_matches + vp_matches\n",
        "    return matches\n",
        "\n",
        "# Test the regex parser\n",
        "sentence = \"The quick brown fox jumps over the lazy dog\"\n",
        "matches = parse_sentence(sentence)\n",
        "\n",
        "print(\"\\nParsed Phrases:\")\n",
        "for phrase, label in matches:\n",
        "    print(f\"{label}: {phrase}\")\n",
        "    #22BCE8674"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Io1TAYtF1mU8",
        "outputId": "0ef5cbf8-92b8-495b-d3ed-245ea4cc0eff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n",
            "POS Tags: ['DT', 'ADJ', 'ADJ', 'NN', 'V', 'IN', 'DT', 'ADJ', 'NN']\n",
            "\n",
            "Parsed Phrases:\n",
            "NP: the lazy dog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement dependency parsing for:\n",
        "-> I prefer the morning flight through Denver\n",
        "-> The dog barked loudly at the strager"
      ],
      "metadata": {
        "id": "QYIYArgE58Yi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Grammar rules for POS tagging\n",
        "pos_rules = {\n",
        "    \"DET\": r\"^(that|this|a|the)$\",\n",
        "    \"Noun\": r\"^(book|flight|meal|man|dog|stranger|morning|Denver)$\",\n",
        "    \"Verb\": r\"^(prefer|barked|read|book|include)$\",\n",
        "    \"Aux\": r\"^(do|does|did|can|will)$\",\n",
        "}\n",
        "\n",
        "# Grammar rules for dependency parsing\n",
        "grammar_rules = {\n",
        "    \"S\": [\"NP VP\", \"VP\", \"Aux NP VP\"],\n",
        "    \"NP\": [\"DET NOM\"],\n",
        "    \"NOM\": [\"Noun\", \"Noun NOM\"],\n",
        "    \"VP\": [\"Verb\", \"Verb NP\"],\n",
        "}\n",
        "\n",
        "def tokenize(sentence):\n",
        "    \"\"\"Tokenize the sentence into words.\"\"\"\n",
        "    return sentence.split()\n",
        "\n",
        "def pos_tag(tokens):\n",
        "    \"\"\"Assign POS tags to tokens using regex.\"\"\"\n",
        "    pos_tags = []\n",
        "    for token in tokens:\n",
        "        for pos, pattern in pos_rules.items():\n",
        "            if re.match(pattern, token):\n",
        "                pos_tags.append((token, pos))\n",
        "                break\n",
        "        else:\n",
        "            pos_tags.append((token, \"UNKNOWN\"))  # Unknown POS\n",
        "    return pos_tags\n",
        "\n",
        "def parse_sentence(sentence):\n",
        "    \"\"\"Parse the sentence and identify dependencies.\"\"\"\n",
        "    tokens = tokenize(sentence)\n",
        "    pos_tags = pos_tag(tokens)\n",
        "    print(\"Tokens:\", tokens)\n",
        "    print(\"POS Tags:\", pos_tags)\n",
        "\n",
        "    dependencies = []\n",
        "\n",
        "    # Parse NP (Noun Phrase)\n",
        "    for i in range(len(pos_tags)):\n",
        "        token, pos = pos_tags[i]\n",
        "        if pos == \"DET\":\n",
        "            # Check if the next word is a Noun\n",
        "            if i + 1 < len(pos_tags) and pos_tags[i + 1][1] == \"Noun\":\n",
        "                dependencies.append((pos_tags[i + 1][0], \"DET\", token))  # Noun depends on DET\n",
        "\n",
        "    # Parse VP (Verb Phrase)\n",
        "    for i in range(len(pos_tags)):\n",
        "        token, pos = pos_tags[i]\n",
        "        if pos == \"Verb\":\n",
        "            # Check if the next word is an NP\n",
        "            if i + 1 < len(pos_tags) and pos_tags[i + 1][1] in [\"DET\", \"Noun\"]:\n",
        "                dependencies.append((pos_tags[i + 1][0], \"OBJ\", token))  # NP depends on Verb as object\n",
        "            # Check if the previous word is an NP\n",
        "            if i - 1 >= 0 and pos_tags[i - 1][1] in [\"DET\", \"Noun\"]:\n",
        "                dependencies.append((token, \"SUBJ\", pos_tags[i - 1][0]))  # Verb depends on NP as subject\n",
        "\n",
        "    return dependencies\n",
        "\n",
        "# Test the dependency parser\n",
        "sentences = [\n",
        "    \"I prefer the morning flight through Denver\",\n",
        "    \"The dog barked loudly at the stranger\",\n",
        "    \"The man read this book\",\n",
        "]\n",
        "\n",
        "for sentence in sentences:\n",
        "    print(f\"\\nSentence: {sentence}\")\n",
        "    dependencies = parse_sentence(sentence)\n",
        "    print(\"Dependencies:\")\n",
        "    for dep in dependencies:\n",
        "        print(f\"{dep[0]} --({dep[1]})--> {dep[2]}\")\n",
        "        #22BCE8674"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srpo-asL6Wo0",
        "outputId": "7daa7878-4c93-4734-86a7-1e90a4a40170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentence: I prefer the morning flight through Denver\n",
            "Tokens: ['I', 'prefer', 'the', 'morning', 'flight', 'through', 'Denver']\n",
            "POS Tags: [('I', 'UNKNOWN'), ('prefer', 'Verb'), ('the', 'DET'), ('morning', 'Noun'), ('flight', 'Noun'), ('through', 'UNKNOWN'), ('Denver', 'Noun')]\n",
            "Dependencies:\n",
            "morning --(DET)--> the\n",
            "the --(OBJ)--> prefer\n",
            "\n",
            "Sentence: The dog barked loudly at the stranger\n",
            "Tokens: ['The', 'dog', 'barked', 'loudly', 'at', 'the', 'stranger']\n",
            "POS Tags: [('The', 'UNKNOWN'), ('dog', 'Noun'), ('barked', 'Verb'), ('loudly', 'UNKNOWN'), ('at', 'UNKNOWN'), ('the', 'DET'), ('stranger', 'Noun')]\n",
            "Dependencies:\n",
            "stranger --(DET)--> the\n",
            "barked --(SUBJ)--> dog\n",
            "\n",
            "Sentence: The man read this book\n",
            "Tokens: ['The', 'man', 'read', 'this', 'book']\n",
            "POS Tags: [('The', 'UNKNOWN'), ('man', 'Noun'), ('read', 'Verb'), ('this', 'DET'), ('book', 'Noun')]\n",
            "Dependencies:\n",
            "book --(DET)--> this\n",
            "this --(OBJ)--> read\n",
            "read --(SUBJ)--> man\n"
          ]
        }
      ]
    }
  ]
}